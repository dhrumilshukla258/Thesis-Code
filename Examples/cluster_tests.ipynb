{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import shutil\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading all the Img Freq csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgFreq = {}\n",
    "#,'CPAC','EPAC','IO','SHEM','WPAC'\n",
    "fList = ['19H','19V','19','22V','37V','37H','37','91H','91V','91','150H','183_1H','183_3H','183_7H']\n",
    "rList = ['ATL']\n",
    "for r in rList:\n",
    "    imgFreq[r] = {}\n",
    "    for f in fList:\n",
    "        imgFreq[r][f] = pd.read_csv(\"..//ImagesPerFreq//\"+r+\"_\"+f+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='..\\\\LogFile\\\\logFile_cluster_6',level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mpl_logger = logging.getLogger(\"matplotlib\")\n",
    "mpl_logger.setLevel(logging.WARNING)\n",
    "from scipy import stats\n",
    "import scipy\n",
    "from numpy import zeros, newaxis\n",
    "\n",
    "class Octants():\n",
    "    def __init__(self):\n",
    "        self.o = {}\n",
    "        \n",
    "    def Calculate(self, w, ringsize):\n",
    "        if self.o.get(str(w)+\"_\"+str(ringsize)) != None:\n",
    "            return copy.deepcopy(self.o[str(w)+\"_\"+str(ringsize)])\n",
    "        print(\"Calculating Octant\")\n",
    "        #width and height always same\n",
    "        h=w\n",
    "        arr = np.zeros((w,h),dtype=np.object)\n",
    "        sectionArr = np.zeros((w,h), dtype=int)\n",
    "        for i in range(w):\n",
    "            for j in range(h):\n",
    "                arr[i][j] = ( i-int(w/2), j-int(h/2) )\n",
    "        \n",
    "        # Creating Sections : We will add all the indices i.e ( (0,0) (1,0).....(n,m) ) to where they belong\n",
    "        # in the section\n",
    "        totalRing = len(ringsize)\n",
    "        section = {}\n",
    "        for i in range(int(totalRing)):\n",
    "            section[i] = {}\n",
    "            for j in range(8):\n",
    "                section[i][j] = []            \n",
    "        \n",
    "        \n",
    "        t1 = int(w/2)\n",
    "        for k in range(1, int(totalRing+1) ):\n",
    "            t2 = int ( ringsize[k-1]/2 )\n",
    "            newArr = arr[  t1-t2:t1+t2, t1-t2:t1+t2 ]\n",
    "            \n",
    "            cenI = int ( newArr.shape[0]/2 )\n",
    "            cenJ = int ( newArr.shape[1]/2 )\n",
    "            preRing = int( ringsize[k-2]/2 )\n",
    "            curRing = t2\n",
    "            \n",
    "            for i in range(newArr.shape[0]):\n",
    "                for j in range(newArr.shape[1]):\n",
    "                    \n",
    "                    distance = math.sqrt( ( ( cenI-i)**2 ) + ( (cenJ-j)**2 ) )\n",
    "                    \n",
    "                    # Below are the edge cases : Same indices were added in 2 different sections\n",
    "                    # To resolve I added these two condition\n",
    "                    if k==totalRing:\n",
    "                        if distance < preRing:\n",
    "                            continue\n",
    "                    elif k==1:\n",
    "                        if distance>=curRing:\n",
    "                            continue\n",
    "                    else:\n",
    "                        if distance < preRing or distance>=curRing:\n",
    "                            continue\n",
    "                    \n",
    "                    # If above cases doesn't occur then the distance is such that its greater than\n",
    "                    # previous Ring size and smaller than current Ring size\n",
    "                    \n",
    "                    # Once the circle is known we need to find the section where it belongs\n",
    "                    # Angle helps in determing exactly where the indice belongs\n",
    "                    angle = math.atan2( newArr[i][j][1], newArr[i][j][0] ) * 180 / np.pi\n",
    "                    angle+=180\n",
    "                    angle%=360\n",
    "\n",
    "                    #Adding it in octants\n",
    "                    if angle >= 0 and angle < 45:\n",
    "                        section[k-1][0].append( ( newArr[i,j][0]+int(w/2), newArr[i,j][1]+int(h/2) ) )\n",
    "                    elif angle >= 45 and angle < 90:\n",
    "                        section[k-1][1].append( ( newArr[i,j][0]+int(w/2), newArr[i,j][1]+int(h/2) ) )\n",
    "                    elif angle >= 90 and angle < 135:\n",
    "                        section[k-1][2].append( ( newArr[i,j][0]+int(w/2), newArr[i,j][1]+int(h/2) ) )\n",
    "                    elif angle >= 135 and angle < 180:\n",
    "                        section[k-1][3].append( ( newArr[i,j][0]+int(w/2), newArr[i,j][1]+int(h/2) ) )\n",
    "                    elif angle >= 180 and angle < 225:\n",
    "                        section[k-1][4].append( ( newArr[i,j][0]+int(w/2), newArr[i,j][1]+int(h/2) ) )\n",
    "                    elif angle >= 225 and angle < 270:\n",
    "                        section[k-1][5].append( ( newArr[i,j][0]+int(w/2), newArr[i,j][1]+int(h/2) ) )\n",
    "                    elif angle >= 270 and angle < 315:\n",
    "                        section[k-1][6].append( ( newArr[i,j][0]+int(w/2), newArr[i,j][1]+int(h/2) ) )\n",
    "                    elif angle >= 315 and angle < 360:\n",
    "                        section[k-1][7].append( ( newArr[i,j][0]+int(w/2), newArr[i,j][1]+int(h/2) ) )\n",
    "    \n",
    "        \n",
    "        # Assigning Each section a unique number\n",
    "        app = {}\n",
    "        totalSection = 0\n",
    "        for i in range(totalRing):\n",
    "            app[i] = {}\n",
    "            for j in range(8):\n",
    "                if app[i].get(j) == None:\n",
    "                    app[i][j]=totalSection\n",
    "                    totalSection+=1\n",
    "        \n",
    "        # Each Indices are given a section number where it belongs\n",
    "        for i in range(totalRing):\n",
    "            for j in range(8):\n",
    "                for k in section[i][j]:\n",
    "                    sectionArr[k[0],k[1]] = int(app[i][j])\n",
    "\n",
    "        self.o[str(w)+\"_\"+str(ringsize)] = (sectionArr, totalSection )\n",
    "        \n",
    "        return copy.deepcopy(self.o[str(w)+\"_\"+str(ringsize)])\n",
    "    \n",
    "    def Draw(self,w,ringsize):\n",
    "        if self.o.get(str(w)+\"_\"+str(ringsize)) != None:\n",
    "            sectionArr, totalSection = self.o[str(w)+\"_\"+str(ringsize)]\n",
    "        else:\n",
    "            sectionArr, totalSection = self.Calculate( w, ringsize )\n",
    "        \n",
    "        #Code to print the maps of octants\n",
    "        x = {}\n",
    "        y = {}\n",
    "        for i in range(w):\n",
    "            for j in range(w):\n",
    "                if x.get(sectionArr[i][j]) == None:\n",
    "                    x[sectionArr[i][j]] = []\n",
    "                if y.get(sectionArr[i][j]) == None:\n",
    "                    y[sectionArr[i][j]] = []\n",
    "                x[sectionArr[i][j]].append(i)\n",
    "                y[sectionArr[i][j]].append(j)\n",
    "\n",
    "        for k in range(totalSection):\n",
    "            plt.scatter(x[k], y[k])\n",
    "       \n",
    "                \n",
    "    def Parameters(self, matrix, w, ringsize, channel):\n",
    "        if self.o.get(str(w)+\"_\"+str(ringsize)) != None:\n",
    "            sectionArr, totalSection = copy.deepcopy(self.o[str(w)+\"_\"+str(ringsize)])\n",
    "        else:\n",
    "            sectionArr, totalSection = self.Calculate( w, ringsize )\n",
    "        \n",
    "        param = np.zeros(( totalSection*6*channel ))\n",
    "        try:\n",
    "            if channel == 1:\n",
    "                mainMap = cv2.cvtColor(matrix, cv2.COLOR_BGR2GRAY).flatten()\n",
    "                sectionArr = sectionArr.flatten()\n",
    "\n",
    "                t = 0\n",
    "                for i in range(totalSection):\n",
    "                    result = np.where(sectionArr == i)\n",
    "                    miniArr = mainMap[result]\n",
    "                    param[t] = np.subtract(*np.percentile(miniArr, [75, 25]))\n",
    "                    param[t+1] = np.mean(miniArr)\n",
    "                    param[t+2] = np.median(miniArr)\n",
    "                    param[t+3] = np.std(miniArr) \n",
    "                    param[t+4] = np.min(miniArr)\n",
    "                    param[t+5] = np.max(miniArr)\n",
    "                    t+=6\n",
    "\n",
    "            else:\n",
    "                mainMap = matrix\n",
    "\n",
    "                t = 0\n",
    "                for i in range(totalSection):\n",
    "                    result = np.where(sectionArr == i)\n",
    "                    miniArr = mainMap[result]\n",
    "                    for j in range(3):\n",
    "                        param[t] = np.subtract(*np.percentile(miniArr[:,j], [75, 25]))\n",
    "                        param[t+1] = np.mean(miniArr[:,j])\n",
    "                        param[t+2] = np.median(miniArr[:,j])\n",
    "                        param[t+3] = np.std(miniArr[:,j]) \n",
    "                        param[t+4] = np.min(miniArr[:,j])\n",
    "                        param[t+5] = np.max(miniArr[:,j])\n",
    "                        t+=6\n",
    "        except:\n",
    "            logging.warning(\"Error in Parameters Function of Octant Class: \", sys.exc_info()[0] )\n",
    "            \n",
    "        return param\n",
    "    \n",
    "    def CreateImage(self,param_matrix,w,ringsize,channel,t_path,clusterNo):\n",
    "        if self.o.get(str(w)+\"_\"+str(ringsize)) != None:\n",
    "            sectionArr, totalSection = copy.deepcopy(self.o[str(w)+\"_\"+str(ringsize)])\n",
    "        else:\n",
    "            sectionArr, totalSection = self.Calculate( w, ringsize )\n",
    "        \n",
    "        statArr = [\"IQR\", \"Mean\", \"Median\", \"STD\", \"Min\", \"Max\"]\n",
    "        for stat in statArr:\n",
    "            if os.path.isdir(t_path+stat) == False:\n",
    "                os.mkdir(t_path+stat)\n",
    "        try:\n",
    "            if channel == 1:\n",
    "                img = np.zeros((w,w))\n",
    "\n",
    "                for i in range(6):\n",
    "                    t = i\n",
    "                    for j in range(totalSection):\n",
    "                        result = np.where(sectionArr == j)\n",
    "                        img[result] = param_matrix[t]\n",
    "                        t+=6\n",
    "                    img = img.astype(np.uint8)\n",
    "                    cv2.imwrite(t_path+statArr[i]+\"//cluster_\"+str(clusterNo)+\".png\",img)\n",
    "\n",
    "            else:\n",
    "                img = np.zeros((w,w,channel))\n",
    "                for i in range(6):\n",
    "                    t = i\n",
    "                    for j in range(totalSection):\n",
    "                        result = np.where(sectionArr == j)\n",
    "                        parameters = []\n",
    "                        for k in range(3):\n",
    "                            parameters.append(param_matrix[t])\n",
    "                            t+=6\n",
    "                        img[result] = parameters\n",
    "\n",
    "                    img = img.astype(np.uint8)\n",
    "                    cv2.imwrite(t_path+statArr[i]+\"//cluster_\"+str(clusterNo)+\".png\",img)\n",
    "        except:\n",
    "            logging.warning(\"Error in CreateImage Function of Octant Class: \", sys.exc_info()[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octa = Octants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionArr, totalSection = octa.Calculate(360,[10,20,30,40,50,60,80,100,120,140,170,200,230,260,270,300,330,361])\n",
    "octa.Draw(360,[10,20,30,40,50,60,80,100,120,140,170,200,230,260,270,300,330,361])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octa.Draw(120,[5,10,15,20,25,30,35,40,50,60,70,90,121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataSelection():\n",
    "    global octa\n",
    "    def __init__( self, _df, area, resolution, channel, ringsize ):\n",
    "        # Consider area according to criteria below\n",
    "        self.df = _df.loc[_df['Area'] >= area]\n",
    "        \n",
    "        self.w = resolution[0]\n",
    "        self.h = resolution[1]\n",
    "        self.channel = channel\n",
    "        self.ringsize = ringsize\n",
    "        \n",
    "    def StartSelection(self):\n",
    "        if self.ringsize != 0:\n",
    "            return self.__Octant()\n",
    "        else:\n",
    "            return self.__AllPixel()\n",
    "    \n",
    "    def __Octant(self):\n",
    "\n",
    "        section, totalSection = octa.Calculate(self.w, self.ringsize)\n",
    "        \n",
    "        # Here instead of considering all pixels we consider statistical value of each sections\n",
    "        # 8 is the image divided in octants\n",
    "        # 6 is total statistical values like mean, median, maximum, minimum, standard deviation \n",
    "        # and interquartile range for each section\n",
    "        matOfImages = np.zeros( ( len(self.df), ( self.channel * totalSection * 6 ) ) )\n",
    "        \n",
    "        i = 0\n",
    "        for index, row in self.df.iterrows():\n",
    "            imgName = row.FileName\n",
    "\n",
    "            # Read ImageFiles and Not Considering Alpha Value just BGR is considered\n",
    "            try:\n",
    "                img_cv = cv2.imread(imgName) \n",
    "            except:\n",
    "                print(\"Error in reading Image: \",imgName)\n",
    "            \n",
    "            try:\n",
    "                img_cv = cv2.resize(img_cv, (self.w, self.h) )\n",
    "            except:\n",
    "                print(\"Resize Image Error: \",imgName)\n",
    "            matOfImages[i] = octa.Parameters(img_cv, self.w, self.ringsize, self.channel)\n",
    "            i+=1\n",
    "        \n",
    "        return matOfImages, self.df\n",
    "    \n",
    "    def __AllPixel(self):\n",
    "        # Creating Matrix of Images, each image considers all pixels\n",
    "        # +2 removed\n",
    "        matOfImages = np.zeros( ( len(self.df), ( self.channel * self.w * self.h ) ) )\n",
    "\n",
    "        i = 0\n",
    "        for index, row in self.df.iterrows():\n",
    "            imgName = row.FileName\n",
    "\n",
    "            # Read ImageFiles and Not Considering Alpha Value just BGR is considered\n",
    "            try:\n",
    "                img_cv = cv2.imread(imgName) \n",
    "            except:\n",
    "                print(\"Error in reading Image: \",imgName)\n",
    "            \n",
    "            try:\n",
    "                img_cv = cv2.resize(img_cv, (self.w, self.h) )\n",
    "            except:\n",
    "                print(\"Resize Error: \",imgName)\n",
    "                \n",
    "            if self.channel == 1:\n",
    "                mainMap = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY).flatten()\n",
    "            else:\n",
    "                mainMap = img_cv.flatten()\n",
    "\n",
    "            #alldata = np.append(mainMap, [row[3],row[4]], axis=0)\n",
    "            matOfImages[i] = mainMap\n",
    "            i+=1\n",
    "        \n",
    "        return matOfImages, self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "mpl_logger = logging.getLogger(\"matplotlib\")\n",
    "mpl_logger.setLevel(logging.WARNING)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import copy\n",
    "import math\n",
    "\n",
    "def FuzzySimilarity(x,c):\n",
    "    #x [ 1, 2 ,3 ,4 ] c[ 0 ,1 ,2 ,3]    \n",
    "    A = np.minimum(x,c)\n",
    "    B = np.maximum(x,c)\n",
    "    return (np.sum(A) + 1) / (np.sum(B) + 2)\n",
    "\n",
    "class Clustering():\n",
    "    def __init__(self,x,clusterSize=2,max_iter=300):\n",
    "        self.k = clusterSize\n",
    "        self.m = x.shape[0]\n",
    "        self.p = x.shape[1]\n",
    "        self.x = x\n",
    "        max_x = np.amax(self.x, axis=0)\n",
    "        max_x[max_x == 0] = 1\n",
    "        self.norm_x = self.x / max_x\n",
    "        self.max_iter = max_iter\n",
    "        self.n_iter = 0\n",
    "        self.labels = []\n",
    "        self.cluster_centers = np.zeros((self.k,self.p))\n",
    "\n",
    "    def Fuzzy_K_Means(self,w1=1.0,w2=1.0,w3=1.0):\n",
    "        prevC = np.random.rand(self.k,self.p)\n",
    "        rand_center_index = random.sample(range(0, self.m), self.k)\n",
    "        \n",
    "        # Randomly assigning each cluster center\n",
    "        # a unique x (whose index lies from 0 to m)\n",
    "        for j in range(self.k):\n",
    "            self.cluster_centers[j,:] = self.norm_x[rand_center_index[j],:] \n",
    "        \n",
    "        for i in range(self.m):\n",
    "            self.labels.append(0)\n",
    "\n",
    "        isConverged = False\n",
    "        while not isConverged and self.n_iter<self.max_iter:\n",
    "            #Assigning each images to cluster where it belongs \n",
    "            for i in range(self.m):    \n",
    "                maxSimilarity = -math.inf\n",
    "                index = -1\n",
    "                for j in range(self.k):\n",
    "                    #Calculating Similarity for Image, Pressure and Wind\n",
    "                    #s1 = FuzzySimilarity(self.norm_x[i,0:self.p-2],self.cluster_centers[j,0:self.p-2])\n",
    "                    #s2 = FuzzySimilarity(self.norm_x[i,self.p-2:self.p-1],self.cluster_centers[j,self.p-2:self.p-1])\n",
    "                    #s3 = FuzzySimilarity(self.norm_x[i,self.p-1:self.p],self.cluster_centers[j,self.p-1:self.p])\n",
    "                    #fs = ( (w1*s1) + (w2*s2) + (w3*s3) ) / (w1+w2+w3)\n",
    "                    fs = FuzzySimilarity(self.norm_x[i,:],self.cluster_centers[j,:])\n",
    "                    if maxSimilarity < fs:\n",
    "                        maxSimilarity = fs\n",
    "                        index = j\n",
    "\n",
    "                # Assigning cluster(1...k) to each images based on MaxSimilarity value\n",
    "                self.labels[i] = index\n",
    "\n",
    "\n",
    "            # Iterating through each images\n",
    "            # Each labels determine unique cluster, images are assigned to\n",
    "            total = np.zeros((self.k,self.p+1))\n",
    "            for i in range(self.m):\n",
    "                total[self.labels[i],0] += 1 \n",
    "                total[self.labels[i],1:] += self.norm_x[i,:]\n",
    "\n",
    "            # Updating cluster center            \n",
    "            for j in range(self.k):\n",
    "                self.cluster_centers[j,:] = total[j,1:]/ (total[j,0])\n",
    "                \n",
    "            if (prevC == self.cluster_centers).all():\n",
    "                isConverged = True\n",
    "\n",
    "            self.n_iter+=1     \n",
    "            prevC = copy.deepcopy(self.cluster_centers)\n",
    "            \n",
    "        self.cluster_centers *= np.amax(self.x, axis=0)\n",
    "        self.silhouetteAvg = silhouette_score(self.x, self.labels)\n",
    "        self.silhouetteValues = silhouette_samples(self.x, self.labels)\n",
    "    \n",
    "    def Scikit_K_Means(self):\n",
    "        kmeans = KMeans(n_clusters=self.k,max_iter=self.max_iter).fit(self.x)\n",
    "        self.cluster_centers = kmeans.cluster_centers_\n",
    "        self.n_iter = kmeans.n_iter_\n",
    "        self.labels = kmeans.labels_\n",
    "        self.silhouetteAvg = silhouette_score(self.x, self.labels)\n",
    "        self.silhouetteValues = silhouette_samples(self.x, self.labels)\n",
    "        \n",
    "    def __fancy_dendrogram(self, *args, **kwargs):\n",
    "        max_d = kwargs.pop('max_d', None)\n",
    "        if max_d and 'color_threshold' not in kwargs:\n",
    "            kwargs['color_threshold'] = max_d\n",
    "        annotate_above = kwargs.pop('annotate_above', 0)\n",
    "\n",
    "        ddata = dendrogram(*args, **kwargs)\n",
    "\n",
    "        if not kwargs.get('no_plot', False):\n",
    "            plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
    "            plt.xlabel('sample index or (cluster size)')\n",
    "            plt.ylabel('distance')\n",
    "            for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
    "                x = 0.5 * sum(i[1:3])\n",
    "                y = d[1]\n",
    "                if y > annotate_above:\n",
    "                    plt.plot(x, y, 'o', c=c)\n",
    "                    plt.annotate(\"%0.3g\" % y, (x, y), xytext=(0, -5),\n",
    "                                 textcoords='offset points',\n",
    "                                 va='top', ha='center')\n",
    "            if max_d:\n",
    "                plt.axhline(y=max_d, c='k')\n",
    "        return ddata\n",
    "    \n",
    "    \n",
    "    def Scipy_Agglomerative(self, dist_m, link_m, path):\n",
    "        Z = linkage(self.x,method=link_m,metric=dist_m)\n",
    "        label_ans = fcluster(Z, t=int(self.k), criterion='maxclust')\n",
    "        fig, axes= plt.subplots(nrows=1, ncols=1,figsize=(30,15))\n",
    "        \n",
    "        dn = self.__fancy_dendrogram(Z, \n",
    "                        labels=label_ans, \n",
    "                        ax=axes, \n",
    "                        truncate_mode='lastp', \n",
    "                        p=int(self.k), \n",
    "                        orientation='top',\n",
    "                        get_leaves = True,\n",
    "                        annotate_above=10,\n",
    "                        show_leaf_counts = True,\n",
    "                        leaf_rotation = 90,\n",
    "                        leaf_font_size = 20\n",
    "                       )\n",
    "        \n",
    "        with open(path+\"dendogram_lastp_\"+str(self.k)+\".json\", 'w') as f:\n",
    "            json.dump(dn, f)\n",
    "        \n",
    "        plt.savefig(path+\"dendrogram_lastp_\"+str(self.k)+\".png\",format=\"png\")\n",
    "        \n",
    "        #dn = dendrogram(Z, labels=label_ans, ax=axes, truncate_mode='level', p=i, orientation='top')\n",
    "        #plt.savefig(path+\"dendrogram_level_\"+str(i)+\".png\",format=\"png\")\n",
    "        \n",
    "        plt.close()\n",
    "        \n",
    "        self.labels = label_ans\n",
    "        self.labels = [x - 1 for x in self.labels]\n",
    "        self.silhouetteAvg = silhouette_score(self.x, self.labels)\n",
    "        self.silhouetteValues = silhouette_samples(self.x, self.labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "class TestCases:\n",
    "    global octa\n",
    "    def __init__(self):\n",
    "        self.testMethods = {}\n",
    "        self.testMethods[\"agglo\"] = pd.read_csv('testcases\\\\agglo.csv')\n",
    "        self.testMethods[\"kmeans\"] = pd.read_csv('testcases\\\\kmeans.csv')\n",
    "        self.testMethods[\"fuzzykmeans\"] = pd.read_csv('testcases\\\\fuzzykmeans.csv')\n",
    "        for k,v in self.testMethods.items():\n",
    "            self.testMethods[k].ResolutionX = self.testMethods[k].ResolutionX.astype(int)\n",
    "            self.testMethods[k].ResolutionY = self.testMethods[k].ResolutionY.astype(int)\n",
    "            self.testMethods[k].Channel = self.testMethods[k].Channel.astype(int)\n",
    "            self.testMethods[k].ClusterSize = self.testMethods[k].ClusterSize.astype(int)\n",
    "            self.testMethods[k].MaxIter = self.testMethods[k].MaxIter.astype(int)\n",
    "            self.testMethods[k].RingSize = self.testMethods[k].RingSize.apply(literal_eval)\n",
    "            \n",
    "    def RunTestCase(self, k,_df, test, t_path):\n",
    "        start_1 = time.time()\n",
    "        tds = TestDataSelection(_df,\n",
    "                                test.Area, \n",
    "                                (test.ResolutionX,test.ResolutionY),\n",
    "                                test.Channel,\n",
    "                                test.RingSize\n",
    "                               )\n",
    "        \n",
    "        matrix, df = tds.StartSelection()\n",
    "        \n",
    "        cL = Clustering(matrix,\n",
    "                        test.ClusterSize,\n",
    "                        test.MaxIter\n",
    "                       )\n",
    "        \n",
    "        end_1 = time.time()\n",
    "        logging.debug(\"Time taken for Data Selection: \" + str((end_1-start_1)/60) + \" min\")\n",
    "        \n",
    "        start_2 = time.time()\n",
    "                \n",
    "        if k == \"kmeans\":\n",
    "            cL.Scikit_K_Means()\n",
    "        elif k == \"agglo\":\n",
    "            cL.Scipy_Agglomerative(test.DistanceMetric,\n",
    "                                   test.Linkage,\n",
    "                                   t_path\n",
    "                                  )\n",
    "        elif k == \"fuzzykmeans\":\n",
    "            cL.Fuzzy_K_Means(test.ImageWeight,\n",
    "                             test.PressureWeight,\n",
    "                             test.WindWeight\n",
    "                            )\n",
    "\n",
    "        end_2 = time.time()\n",
    "\n",
    "        logging.debug(\"Average silhouette score for \"+str(cL.k)+\" cluster : \"+str(cL.silhouetteAvg) )\n",
    "        logging.debug(\"Time taken by Clustering Algorithm: \" + str((end_2-start_2)/60) + \" min\")\n",
    "        \n",
    "        # Creating K cluster folders\n",
    "        # Creating Images for according to cluster centers\n",
    "        for i in range(int(cL.k)):\n",
    "            if k==\"fuzzykmeans\" or k==\"kmeans\":\n",
    "                img = cL.cluster_centers[i,0 : ( test.Channel * test.ResolutionX * test.ResolutionY ) ]\n",
    "                \n",
    "                if test.RingSize != 0:\n",
    "                    octa.CreateImage(img, \n",
    "                                     test.ResolutionX,\n",
    "                                     test.RingSize,\n",
    "                                     test.Channel,\n",
    "                                     t_path,\n",
    "                                     i)\n",
    "                else:\n",
    "                    if test.Channel == 1:\n",
    "                        img = img.reshape(test.ResolutionX,test.ResolutionY)\n",
    "                    else:\n",
    "                        img = img.reshape(test.ResolutionX,test.ResolutionY,3)\n",
    "                    img = img.astype(np.uint8)\n",
    "                    cv2.imwrite(t_path+\"cluster_\"+str(i)+\".png\",img)\n",
    "            \n",
    "                \n",
    "            #os.mkdir(t_path+str(i))\n",
    "        \n",
    "        \n",
    "        #Create CSV with Image, ClusterLabel and Silhouette value\n",
    "        image = pd.DataFrame({ 'FileName':df.FileName, 'ClusterLabel':cL.labels, 'SilhouetteVal':cL.silhouetteValues, 'T_No':df.T_No}) \n",
    "        image.to_csv(t_path+\"testInfo.csv\",index = False)\n",
    "        \n",
    "    def RunTests(self,_df,region,freq):\n",
    "        for k,test in self.testMethods.items():\n",
    "            path = \"..//..//AllFrequencies//\"+region+\"//\"+freq+\"//\"+k+\"//\"\n",
    "            \n",
    "            if os.path.isdir(path) == False:\n",
    "                os.mkdir(path)\n",
    "\n",
    "            for case in range(len(test)):\n",
    "                if int(test.TestNo.iloc[case][5:]) == 13:\n",
    "                    start_1 = time.time()\n",
    "\n",
    "                    # Creating a Test Directory\n",
    "                    t_path = path + test.TestNo.iloc[case]\n",
    "                    print(t_path)\n",
    "                    if os.path.isdir(t_path):\n",
    "                        continue\n",
    "                    os.mkdir(t_path)\n",
    "                    t_path+=\"//\"\n",
    "\n",
    "                    logging.debug(\"Path for this Test Case:- \"+t_path)\n",
    "                    \n",
    "                    self.RunTestCase(k,_df,test.iloc[case],t_path)\n",
    "                    \n",
    "                    logging.debug(\"Time taken -> \"+region+\" \"+freq+\" \"+k+\" \"+test.TestNo.iloc[case]+\" : \"+str((time.time()-start_1)/60) + \" min\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TestCases()\n",
    "test.RunTests( imgFreq['ATL']['22V'], 'ATL', '22V' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for region,v1 in imgFreq.items():\n",
    "    for freq, _df in v1.items():\n",
    "        test.RunTests(_df,region,freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 'ATL'\n",
    "f = '19H'\n",
    "imgFreq[r][f].FileName.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.RunTests(imgFreq['ATL']['91V'], 'ATL', '91V' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type ( app.iloc[9] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app =  test.testMethods[\"agglo\"].RingSize.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'ATL'\n",
    "freq = '91V'\n",
    "k = 'agglo'\n",
    "case = 7\n",
    "\n",
    "path = \"..//..//AllFrequencies//\"+region+\"//\"+freq+\"//\"+k+\"//\"\n",
    "t_path = path +\"Test_\"+str(case)\n",
    "if os.path.isdir(t_path):\n",
    "    continue\n",
    "os.mkdir(t_path)\n",
    "t_path+=\"//\"\n",
    "_df\n",
    "\n",
    "self.RunTestCase(k,_df,test.iloc[case],t_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.tstd(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
