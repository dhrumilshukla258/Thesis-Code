{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially we had created images without caring about the colormap of each image<br>\n",
    "And then we identified which matFile consisted of invalid data.<br>\n",
    "This included the automated and manual check we had to do on the images. <br><br>\n",
    "\n",
    "To reduce the computation of checking the criteria of valid or invalid data.<br>\n",
    "We will iterate through the csv files which is collection of valid images<br>\n",
    "And create a json of .mat files consisting of valid frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = json.load( open( \"..\\\\matfiles_and_best_track.json\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgFreq = {}\n",
    "tbsVal = {}\n",
    "fList = ['19H','19V','19','22V','37V','37H','37','91H','91V','91','150H','183_1H','183_3H','183_7H']\n",
    "rList = ['ATL','CPAC','EPAC','IO','SHEM','WPAC']\n",
    "for r in rList:\n",
    "    tbsVal[r] = {}\n",
    "    imgFreq[r] = {}\n",
    "    for f in fList:\n",
    "        tbsVal[r][f] = [[],[]]\n",
    "        imgFreq[r][f] = pd.read_csv(\"..\\\\ImagesPerFreq\\\\\"+r+\"_\"+f+'.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "valid_matfile_and_best_track = {}\n",
    "for r in rList:\n",
    "    for f in fList:\n",
    "        df = imgFreq[r][f]\n",
    "        for index,row in df.iterrows():\n",
    "            m = [m.start() for m in re.finditer(r'//', row.FileName)]\n",
    "    \n",
    "            year = row.FileName[m[2]+2:m[3]]\n",
    "            region = row.FileName[m[3]+2:m[4]]\n",
    "            \n",
    "            stormNo = row.FileName[m[4]+2:m[5]]\n",
    "            f_ = row.FileName[m[5]+2:m[6]]\n",
    "            freq = row.FileName[m[6]+2:m[7]]\n",
    "            matFileName = row.FileName[m[7]+2: len(row.FileName)-4] + \".mat\"\n",
    "            \n",
    "            if valid_matfile_and_best_track.get(region) == None:\n",
    "                valid_matfile_and_best_track[ region ] = {}\n",
    "            if valid_matfile_and_best_track[region].get(year) == None:\n",
    "                valid_matfile_and_best_track[region][year] = {}\n",
    "            if valid_matfile_and_best_track[region][year].get(stormNo) == None:\n",
    "                valid_matfile_and_best_track[region][year][stormNo] = {}\n",
    "            if valid_matfile_and_best_track[region][year][stormNo].get(f_) == None:\n",
    "                valid_matfile_and_best_track[region][year][stormNo][f_] = [ data[region][year][stormNo][f_][0], {}]\n",
    "            \n",
    "            if valid_matfile_and_best_track[region][year][stormNo][f_][1].get(matFileName) == None:\n",
    "                valid_matfile_and_best_track[region][year][stormNo][f_][1][matFileName] = []\n",
    "                \n",
    "            valid_matfile_and_best_track[region][year][stormNo][f_][1][matFileName].append(freq)\n",
    "\n",
    "with open('valid_matfile_and_best_track.json', 'w') as fp:\n",
    "    json.dump(valid_matfile_and_best_track, fp, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to find out Max Min Brightness temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_matfile_and_best_track = json.load( open( \"..\\\\valid_matfiles_and_best_track.json\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tbsVal will contain list of all max and min tbs values for each unique combination of region and freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindMaxMinTbs:\n",
    "    global tbsVal\n",
    "    def __init__(self, matpath):\n",
    "        self.mMatPath = matpath\n",
    "        \n",
    "        self.__mFreq_to_swath = {}\n",
    "        self.__mFreq_to_swath['19']  = [0,[2.400, 1.400]] \n",
    "        self.__mFreq_to_swath['19V'] = [0,0]\n",
    "        self.__mFreq_to_swath['19H'] = [0,1]\n",
    "        self.__mFreq_to_swath['22V'] = [0,2]\n",
    "\n",
    "        self.__mFreq_to_swath['37']  = [1,[2.150, 1.150]]\n",
    "        self.__mFreq_to_swath['37V'] = [1,0]\n",
    "        self.__mFreq_to_swath['37H'] = [1,1]\n",
    "\n",
    "        self.__mFreq_to_swath['91']  = [3,[1.751, 0.751]]\n",
    "        self.__mFreq_to_swath['91V'] = [3,0] \n",
    "        self.__mFreq_to_swath['91H'] = [3,1]\n",
    "\n",
    "        self.__mFreq_to_swath['150H'] = [2,0]\n",
    "        self.__mFreq_to_swath['183_1H'] = [2,1]\n",
    "        self.__mFreq_to_swath['183_3H'] = [2,2]\n",
    "        self.__mFreq_to_swath['183_7H'] = [2,3]\n",
    "     \n",
    "    def PCT_Function(self,v,h,val):\n",
    "        return val[0]*v - val[1]*h\n",
    "    \n",
    "    def ReadMatFile(self,region,matFile,valid_freq):\n",
    "        try:\n",
    "            mat = scipy.io.loadmat(self.mMatPath+matFile)\n",
    "        except:\n",
    "            msg = \"Error Reading File: \" + str( self.mMatPath+matFile ) \n",
    "            print(msg)\n",
    "            #self.__mLog.error( msg )\n",
    "       \n",
    "        swaths = mat[\"passData\"][0][0]\n",
    "        \n",
    "        for freq in valid_freq:\n",
    "            swathList = self.__mFreq_to_swath[freq]\n",
    "            \n",
    "            swath_data = swaths[ swathList[0] ]\n",
    "            lat = swath_data[0][0][1]\n",
    "            lon = swath_data[0][0][2]\n",
    "            channel = swath_data[0][0][3]\n",
    "            \n",
    "             # Calculating PCT values for specific frequencies\n",
    "            if freq == '19' or freq=='37' or freq=='91':\n",
    "                tbs = self.PCT_Function( channel[0], channel[1], swathList[1] )\n",
    "            else:\n",
    "                tbs = channel[swathList[1]]\n",
    "            \n",
    "            if np.any(tbs<320) and np.any(tbs>0):\n",
    "                tbsVal[region][freq][0].append(np.amin(tbs))\n",
    "                tbsVal[region][freq][1].append(np.amax(tbs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over all mat files and find out Max and Min values of each frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time taken: 26.787337613105773 mins\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "for region,v1 in valid_matfile_and_best_track.items():\n",
    "    for year,v2 in v1.items():\n",
    "        for stormNo,stormDict in v2.items():\n",
    "            for f_,files in stormDict.items():\n",
    "                if f_ == \"BestTrack\":\n",
    "                    continue\n",
    "                rootDirOfMatFile = files[0]\n",
    "                matFiles = files[1]\n",
    "                ftbs = FindMaxMinTbs(rootDirOfMatFile)\n",
    "                for filename,valid_freq in matFiles.items():\n",
    "                    ftbs.ReadMatFile(region, filename,valid_freq)\n",
    "print(\"Total Time taken: \"+str( (time.time()-s)/60 )+\" mins\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the Max and Min Tbs Values found after above process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "def MakeDir(path):\n",
    "    if os.path.isdir(path) == False:\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbsVal[\"All\"] = {}\n",
    "for f in fList:\n",
    "    tbsVal[\"All\"][f] =[[],[]]\n",
    "    for i in range(2):\n",
    "        for r in rList:\n",
    "            tbsVal[\"All\"][f][i].extend(tbsVal[r][f][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Histogram Graphs\n",
    "path = os.getcwd()+\"\\\\MaxMinTbs\\\\\"\n",
    "for i in range(2):\n",
    "    mpath = path+str(i)\n",
    "    MakeDir(mpath)\n",
    "    for f in fList:\n",
    "        for r in rList + [\"All\"]:\n",
    "            fpath=mpath+\"\\\\\"+f\n",
    "            MakeDir(fpath)\n",
    "            plt.hist( tbsVal[r][f][i])\n",
    "            meanVal = \"{:.2f}\".format(np.mean(tbsVal[r][f][i]))\n",
    "            stdVal = \"{:.2f}\".format(np.std(tbsVal[r][f][i]))\n",
    "            plt.savefig(fpath+\"\\\\\"+r+\"_\"+meanVal+\"_\"+stdVal+\".png\")\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tables\n",
    "dic_tbs_val = [ [min,{}], [max,{}] ]\n",
    "                 \n",
    "for i in range(2):\n",
    "    for r in rList:\n",
    "        dic_tbs_val[i][1][r] = {}\n",
    "        for f in fList:\n",
    "            dic_tbs_val[i][1][r][f] = [ dic_tbs_val[i][0](tbsVal[r][f][i]), np.mean(tbsVal[r][f][i]), np.std(tbsVal[r][f][i]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.DataFrame(dic_tbs_val[0][1])\n",
    "t2 = pd.DataFrame(dic_tbs_val[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.to_csv(os.getcwd()+\"\\\\minimum.csv\")\n",
    "t2.to_csv(os.getcwd()+\"\\\\maximum.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
