{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Reading Mat File\n",
    "import scipy.io\n",
    "\n",
    "# For reading and creating tables\n",
    "import pandas as pd\n",
    "\n",
    "# To Interpolate storm center lon and lat\n",
    "from scipy import interpolate\n",
    "\n",
    "# For Creating Images\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To find Great Circle Distance\n",
    "from cartopy import geodesic\n",
    "import shapely.geometry as sgeom\n",
    "\n",
    "# For Converting Dates\n",
    "import matplotlib.dates as mpldate\n",
    "\n",
    "# To Mask and Find Land and CoastLine\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shpreader\n",
    "from shapely.ops import unary_union\n",
    "from shapely.prepared import prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Reading Mat File\n",
    "import scipy.io\n",
    "\n",
    "# To find Great Circle Distance\n",
    "from cartopy import geodesic\n",
    "import shapely.geometry as sgeom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0-80km, 0-100km, and 200-400km\n",
    "#col_name = ['0-50','50-100','100-150','150-200','200-250','250-300','300-350','350-400']\n",
    "#col_radius = [(0,50),(50,100),(100,150),(150,200),(200,250),(250,300),(300,350),(350,400)]\n",
    "col_name = ['0-80','0-100','200-400']\n",
    "col_radius = [(0,80),(0,100),(200,400)]\n",
    "map_radius_to_name = {}\n",
    "for i in range(len(col_name)):\n",
    "    map_radius_to_name[col_radius[i]] = col_name[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgFreq = {}\n",
    "fList = ['19H','19V','19','22V','37V','37H','37','91H','91V','91','150H','183_1H','183_3H','183_7H']\n",
    "rList = ['ATL','CPAC','EPAC','IO','SHEM','WPAC']\n",
    "for r in rList:\n",
    "    imgFreq[r] = {}\n",
    "    for f in fList:\n",
    "        if 'H' not in f and 'V' not in f:\n",
    "            imgFreq[r][f] = pd.read_csv(\"..\\\\ImagesPerFreq\\\\\"+r+\"_\"+f+'PCT.csv')\n",
    "        else:\n",
    "            imgFreq[r][f] = pd.read_csv(\"..\\\\ImagesPerFreq\\\\\"+r+\"_\"+f+'.csv')\n",
    "        for rad in col_name:\n",
    "            imgFreq[r][f][rad] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Area</th>\n",
       "      <th>T_No</th>\n",
       "      <th>0-50</th>\n",
       "      <th>50-100</th>\n",
       "      <th>100-150</th>\n",
       "      <th>150-200</th>\n",
       "      <th>200-250</th>\n",
       "      <th>250-300</th>\n",
       "      <th>300-350</th>\n",
       "      <th>350-400</th>\n",
       "      <th>0-80</th>\n",
       "      <th>0-100</th>\n",
       "      <th>200-400</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>..\\..\\MyCreatedData\\5\\ATL\\29\\F16\\19\\20051122T2...</td>\n",
       "      <td>-40.820101</td>\n",
       "      <td>30.037247</td>\n",
       "      <td>984</td>\n",
       "      <td>45</td>\n",
       "      <td>0.731821</td>\n",
       "      <td>3.0</td>\n",
       "      <td>280.577962</td>\n",
       "      <td>281.875653</td>\n",
       "      <td>283.998764</td>\n",
       "      <td>285.439172</td>\n",
       "      <td>286.407243</td>\n",
       "      <td>287.136546</td>\n",
       "      <td>287.556750</td>\n",
       "      <td>287.812071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>..\\..\\MyCreatedData\\5\\ATL\\29\\F16\\19\\20051123T1...</td>\n",
       "      <td>-41.221494</td>\n",
       "      <td>27.498088</td>\n",
       "      <td>983</td>\n",
       "      <td>50</td>\n",
       "      <td>0.990081</td>\n",
       "      <td>3.0</td>\n",
       "      <td>283.010836</td>\n",
       "      <td>283.102151</td>\n",
       "      <td>284.303013</td>\n",
       "      <td>284.894224</td>\n",
       "      <td>285.627855</td>\n",
       "      <td>286.314580</td>\n",
       "      <td>287.155166</td>\n",
       "      <td>288.082327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>..\\..\\MyCreatedData\\5\\ATL\\29\\F16\\19\\20051123T2...</td>\n",
       "      <td>-40.319371</td>\n",
       "      <td>25.653805</td>\n",
       "      <td>982</td>\n",
       "      <td>55</td>\n",
       "      <td>0.997904</td>\n",
       "      <td>3.5</td>\n",
       "      <td>286.988969</td>\n",
       "      <td>285.121665</td>\n",
       "      <td>284.548524</td>\n",
       "      <td>285.720195</td>\n",
       "      <td>287.380519</td>\n",
       "      <td>288.160216</td>\n",
       "      <td>289.081811</td>\n",
       "      <td>289.890177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..\\..\\MyCreatedData\\5\\ATL\\29\\F16\\19\\20051124T1...</td>\n",
       "      <td>-39.045968</td>\n",
       "      <td>24.814455</td>\n",
       "      <td>980</td>\n",
       "      <td>60</td>\n",
       "      <td>0.996655</td>\n",
       "      <td>3.5</td>\n",
       "      <td>283.728767</td>\n",
       "      <td>283.453010</td>\n",
       "      <td>284.355134</td>\n",
       "      <td>284.892815</td>\n",
       "      <td>286.358307</td>\n",
       "      <td>287.842468</td>\n",
       "      <td>288.934561</td>\n",
       "      <td>289.450696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>..\\..\\MyCreatedData\\5\\ATL\\29\\F16\\19\\20051125T1...</td>\n",
       "      <td>-39.561312</td>\n",
       "      <td>23.379201</td>\n",
       "      <td>982</td>\n",
       "      <td>55</td>\n",
       "      <td>0.997899</td>\n",
       "      <td>3.5</td>\n",
       "      <td>285.336194</td>\n",
       "      <td>284.131648</td>\n",
       "      <td>284.881809</td>\n",
       "      <td>286.260307</td>\n",
       "      <td>287.985572</td>\n",
       "      <td>289.228951</td>\n",
       "      <td>289.891106</td>\n",
       "      <td>290.335442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>..\\..\\MyCreatedData\\16\\ATL\\15\\F18\\19\\20161017T...</td>\n",
       "      <td>-42.846875</td>\n",
       "      <td>42.632057</td>\n",
       "      <td>962</td>\n",
       "      <td>65</td>\n",
       "      <td>0.998024</td>\n",
       "      <td>4.0</td>\n",
       "      <td>284.026970</td>\n",
       "      <td>281.497738</td>\n",
       "      <td>280.482932</td>\n",
       "      <td>280.937620</td>\n",
       "      <td>281.888724</td>\n",
       "      <td>282.656251</td>\n",
       "      <td>283.282366</td>\n",
       "      <td>283.330003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>..\\..\\MyCreatedData\\16\\ATL\\15\\F18\\19\\20161018T...</td>\n",
       "      <td>-37.058067</td>\n",
       "      <td>47.672898</td>\n",
       "      <td>969</td>\n",
       "      <td>55</td>\n",
       "      <td>0.291986</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>279.023002</td>\n",
       "      <td>278.468717</td>\n",
       "      <td>278.256106</td>\n",
       "      <td>278.495983</td>\n",
       "      <td>278.263101</td>\n",
       "      <td>279.237673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862</th>\n",
       "      <td>..\\..\\MyCreatedData\\16\\ATL\\69\\F16\\19\\20161102T...</td>\n",
       "      <td>-46.052121</td>\n",
       "      <td>17.591951</td>\n",
       "      <td>1009</td>\n",
       "      <td>20</td>\n",
       "      <td>0.635043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.599187</td>\n",
       "      <td>294.716096</td>\n",
       "      <td>294.919914</td>\n",
       "      <td>295.508521</td>\n",
       "      <td>296.161805</td>\n",
       "      <td>296.151446</td>\n",
       "      <td>296.078709</td>\n",
       "      <td>295.261321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>..\\..\\MyCreatedData\\16\\ATL\\69\\F17\\19\\20161102T...</td>\n",
       "      <td>-46.543180</td>\n",
       "      <td>17.853565</td>\n",
       "      <td>1009</td>\n",
       "      <td>20</td>\n",
       "      <td>0.940508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.043348</td>\n",
       "      <td>291.774440</td>\n",
       "      <td>292.220666</td>\n",
       "      <td>292.619892</td>\n",
       "      <td>292.896426</td>\n",
       "      <td>292.740908</td>\n",
       "      <td>292.479544</td>\n",
       "      <td>292.805927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>..\\..\\MyCreatedData\\16\\ATL\\69\\F18\\19\\20161102T...</td>\n",
       "      <td>-46.461308</td>\n",
       "      <td>17.809973</td>\n",
       "      <td>1009</td>\n",
       "      <td>20</td>\n",
       "      <td>0.690019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.642664</td>\n",
       "      <td>292.140713</td>\n",
       "      <td>293.086501</td>\n",
       "      <td>294.220498</td>\n",
       "      <td>294.239111</td>\n",
       "      <td>294.627146</td>\n",
       "      <td>294.725341</td>\n",
       "      <td>294.813330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3865 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               FileName     CenLon     CenLat  \\\n",
       "0     ..\\..\\MyCreatedData\\5\\ATL\\29\\F16\\19\\20051122T2... -40.820101  30.037247   \n",
       "1     ..\\..\\MyCreatedData\\5\\ATL\\29\\F16\\19\\20051123T1... -41.221494  27.498088   \n",
       "2     ..\\..\\MyCreatedData\\5\\ATL\\29\\F16\\19\\20051123T2... -40.319371  25.653805   \n",
       "3     ..\\..\\MyCreatedData\\5\\ATL\\29\\F16\\19\\20051124T1... -39.045968  24.814455   \n",
       "4     ..\\..\\MyCreatedData\\5\\ATL\\29\\F16\\19\\20051125T1... -39.561312  23.379201   \n",
       "...                                                 ...        ...        ...   \n",
       "3860  ..\\..\\MyCreatedData\\16\\ATL\\15\\F18\\19\\20161017T... -42.846875  42.632057   \n",
       "3861  ..\\..\\MyCreatedData\\16\\ATL\\15\\F18\\19\\20161018T... -37.058067  47.672898   \n",
       "3862  ..\\..\\MyCreatedData\\16\\ATL\\69\\F16\\19\\20161102T... -46.052121  17.591951   \n",
       "3863  ..\\..\\MyCreatedData\\16\\ATL\\69\\F17\\19\\20161102T... -46.543180  17.853565   \n",
       "3864  ..\\..\\MyCreatedData\\16\\ATL\\69\\F18\\19\\20161102T... -46.461308  17.809973   \n",
       "\n",
       "      Pressure  Wind      Area  T_No        0-50      50-100     100-150  \\\n",
       "0          984    45  0.731821   3.0  280.577962  281.875653  283.998764   \n",
       "1          983    50  0.990081   3.0  283.010836  283.102151  284.303013   \n",
       "2          982    55  0.997904   3.5  286.988969  285.121665  284.548524   \n",
       "3          980    60  0.996655   3.5  283.728767  283.453010  284.355134   \n",
       "4          982    55  0.997899   3.5  285.336194  284.131648  284.881809   \n",
       "...        ...   ...       ...   ...         ...         ...         ...   \n",
       "3860       962    65  0.998024   4.0  284.026970  281.497738  280.482932   \n",
       "3861       969    55  0.291986   3.5         NaN         NaN  279.023002   \n",
       "3862      1009    20  0.635043   0.0  294.599187  294.716096  294.919914   \n",
       "3863      1009    20  0.940508   0.0  291.043348  291.774440  292.220666   \n",
       "3864      1009    20  0.690019   0.0  291.642664  292.140713  293.086501   \n",
       "\n",
       "         150-200     200-250     250-300     300-350     350-400  0-80  0-100  \\\n",
       "0     285.439172  286.407243  287.136546  287.556750  287.812071   NaN    NaN   \n",
       "1     284.894224  285.627855  286.314580  287.155166  288.082327   NaN    NaN   \n",
       "2     285.720195  287.380519  288.160216  289.081811  289.890177   NaN    NaN   \n",
       "3     284.892815  286.358307  287.842468  288.934561  289.450696   NaN    NaN   \n",
       "4     286.260307  287.985572  289.228951  289.891106  290.335442   NaN    NaN   \n",
       "...          ...         ...         ...         ...         ...   ...    ...   \n",
       "3860  280.937620  281.888724  282.656251  283.282366  283.330003   NaN    NaN   \n",
       "3861  278.468717  278.256106  278.495983  278.263101  279.237673   NaN    NaN   \n",
       "3862  295.508521  296.161805  296.151446  296.078709  295.261321   NaN    NaN   \n",
       "3863  292.619892  292.896426  292.740908  292.479544  292.805927   NaN    NaN   \n",
       "3864  294.220498  294.239111  294.627146  294.725341  294.813330   NaN    NaN   \n",
       "\n",
       "      200-400  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "...       ...  \n",
       "3860      NaN  \n",
       "3861      NaN  \n",
       "3862      NaN  \n",
       "3863      NaN  \n",
       "3864      NaN  \n",
       "\n",
       "[3865 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgFreq['ATL']['19']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "valid_matfile_and_best_track = {}\n",
    "for r in rList:\n",
    "    for f in fList:\n",
    "        df = imgFreq[r][f]\n",
    "        for index,row in df.iterrows():\n",
    "            m = [m.start() for m in re.finditer(r'\\\\', row.FileName)]\n",
    "            year = row.FileName[m[2]+1:m[3]]\n",
    "            region = row.FileName[m[3]+1:m[4]]\n",
    "            stormNo = row.FileName[m[4]+1:m[5]]\n",
    "            f_ = row.FileName[m[5]+1:m[6]]\n",
    "            freq = row.FileName[m[6]+1:m[7]]\n",
    "            matFileName = row.FileName[ m[7]+1 : m[7]+26] + \".mat\"\n",
    "            \n",
    "            if valid_matfile_and_best_track.get(region) == None:\n",
    "                valid_matfile_and_best_track[ region ] = {}\n",
    "            if valid_matfile_and_best_track[region].get(year) == None:\n",
    "                valid_matfile_and_best_track[region][year] = {}\n",
    "            if valid_matfile_and_best_track[region][year].get(stormNo) == None:\n",
    "                valid_matfile_and_best_track[region][year][stormNo] = {}\n",
    "            if valid_matfile_and_best_track[region][year][stormNo].get(f_) == None:\n",
    "                valid_matfile_and_best_track[region][year][stormNo][f_] = {}\n",
    "            if valid_matfile_and_best_track[region][year][stormNo][f_].get(matFileName) == None:\n",
    "                valid_matfile_and_best_track[region][year][stormNo][f_][matFileName] = []\n",
    "            valid_matfile_and_best_track[region][year][stormNo][f_][matFileName].append([freq,row.CenLon,row.CenLat,row.T_No,index])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('valid_matfile_and_best_track.json', 'w') as fp:\n",
    "    json.dump(valid_matfile_and_best_track, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_matfile_and_best_track = json.load( open( \"valid_matfile_and_best_track.json\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDF_of_Tbs:\n",
    "    global map_radius_to_name\n",
    "    global imgFreq\n",
    "    def __init__(self, matpath):\n",
    "        self.mMatPath = matpath\n",
    "        \n",
    "        self.__mFreq_to_swath = {}\n",
    "        self.__mFreq_to_swath['19']  = [0,[2.400, 1.400]] \n",
    "        self.__mFreq_to_swath['19V'] = [0,0]\n",
    "        self.__mFreq_to_swath['19H'] = [0,1]\n",
    "        self.__mFreq_to_swath['22V'] = [0,2]\n",
    "\n",
    "        self.__mFreq_to_swath['37']  = [1,[2.150, 1.150]]\n",
    "        self.__mFreq_to_swath['37V'] = [1,0]\n",
    "        self.__mFreq_to_swath['37H'] = [1,1]\n",
    "\n",
    "        self.__mFreq_to_swath['91']  = [3,[1.751, 0.751]]\n",
    "        self.__mFreq_to_swath['91V'] = [3,0] \n",
    "        self.__mFreq_to_swath['91H'] = [3,1]\n",
    "\n",
    "        self.__mFreq_to_swath['150H'] = [2,0]\n",
    "        self.__mFreq_to_swath['183_1H'] = [2,1]\n",
    "        self.__mFreq_to_swath['183_3H'] = [2,2]\n",
    "        self.__mFreq_to_swath['183_7H'] = [2,3]\n",
    "     \n",
    "    def PCT_Function(self,v,h,val):\n",
    "        return val[0]*v - val[1]*h\n",
    "    \n",
    "    def ReadMatFile(self,region,matFile,freq_data):\n",
    "        try:\n",
    "            mat = scipy.io.loadmat(self.mMatPath+matFile)\n",
    "        except   Exception as e:\n",
    "            print(e)\n",
    "            msg = \"Error Reading File: \" + str( self.mMatPath+matFile ) \n",
    "            print(msg)\n",
    "            #self.__mLog.error( msg )\n",
    "       \n",
    "        swaths = mat[\"passData\"][0][0]\n",
    "        \n",
    "        for freq,cenLon,cenLat,t_no,index_no in freq_data:\n",
    "            swathList = self.__mFreq_to_swath[freq]\n",
    "            \n",
    "            swath_data = swaths[ swathList[0] ]\n",
    "            lat = swath_data[0][0][1]\n",
    "            lon = swath_data[0][0][2]\n",
    "            channel = swath_data[0][0][3]\n",
    "            # Calculating PCT values for specific frequencies\n",
    "            if freq == '19' or freq=='37' or freq=='91':\n",
    "                tbs = self.PCT_Function( channel[0], channel[1], swathList[1] )\n",
    "            else:\n",
    "                tbs = channel[swathList[1]]\n",
    "            \n",
    "            pre_indices = []\n",
    "            for (r1,r2),col_name in map_radius_to_name.items():#[50,100,150,200,250,300,350,400]:\n",
    "                \n",
    "                def GetIndices(radius):                \n",
    "                    circle= geodesic.Geodesic().circle(cenLon, cenLat, radius*1000)\n",
    "                    poly = sgeom.Polygon(circle)\n",
    "\n",
    "                    #                                 min Lon                max Lon\n",
    "                    result = np.where( (lon>=poly.bounds[0]) & (lon<=poly.bounds[2]) )\n",
    "                    lon_set = set(zip(result[0], result[1]))\n",
    "                    #                                 min Lat                max Lat\n",
    "                    result = np.where( (lat>=poly.bounds[1]) & (lat<=poly.bounds[3]) )\n",
    "                    lat_set = set(zip(result[0], result[1]))\n",
    "                    \n",
    "                    return lon_set.intersection(lat_set)\n",
    "                \n",
    "                curr_indices = list(GetIndices(r1) ^ GetIndices(r2))\n",
    "                \n",
    "                tot_tbs = 0\n",
    "                for i,j in curr_indices:\n",
    "                    tot_tbs+=tbs[i,j]\n",
    "                try:\n",
    "                    avg_tbs = tot_tbs/len(curr_indices)\n",
    "                except ZeroDivisionError:\n",
    "                    #print(\"ZeroDivision for: \",region,freq,matFile[:25],r1,r2)\n",
    "                    continue\n",
    "                \n",
    "                col_index = imgFreq[region][freq].columns.get_loc(col_name)\n",
    "                imgFreq[region][freq].iloc[index_no,col_index] = avg_tbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATL 5\n",
      "ATL 12\n",
      "ATL 6\n",
      "ATL 17\n",
      "ATL 7\n",
      "ATL 8\n",
      "ATL 9\n",
      "ATL 10\n",
      "ATL 18\n",
      "ATL 13\n",
      "ATL 11\n",
      "ATL 14\n",
      "ATL 15\n",
      "ATL 19\n",
      "ATL 16\n",
      "CPAC 6\n",
      "CPAC 9\n",
      "CPAC 18\n",
      "CPAC 13\n",
      "CPAC 14\n",
      "CPAC 15\n",
      "CPAC 19\n",
      "CPAC 16\n",
      "EPAC 12\n",
      "EPAC 6\n",
      "EPAC 17\n",
      "EPAC 7\n",
      "EPAC 8\n",
      "EPAC 9\n",
      "EPAC 10\n",
      "EPAC 18\n",
      "EPAC 13\n",
      "EPAC 11\n",
      "EPAC 14\n",
      "EPAC 15\n",
      "EPAC 19\n",
      "EPAC 16\n",
      "IO 5\n",
      "IO 12\n",
      "IO 17\n",
      "IO 7\n",
      "IO 8\n",
      "IO 9\n",
      "IO 10\n",
      "IO 18\n",
      "IO 13\n",
      "IO 11\n",
      "IO 14\n",
      "IO 15\n",
      "IO 19\n",
      "IO 16\n",
      "SHEM 12\n",
      "SHEM 6\n",
      "SHEM 17\n",
      "SHEM 7\n",
      "SHEM 8\n",
      "SHEM 9\n",
      "SHEM 10\n",
      "SHEM 18\n",
      "SHEM 13\n",
      "SHEM 11\n",
      "SHEM 14\n",
      "SHEM 15\n",
      "SHEM 19\n",
      "SHEM 16\n",
      "WPAC 12\n",
      "WPAC 6\n",
      "WPAC 17\n",
      "WPAC 7\n",
      "WPAC 8\n",
      "WPAC 9\n",
      "WPAC 10\n",
      "WPAC 18\n",
      "WPAC 13\n",
      "WPAC 11\n",
      "WPAC 14\n",
      "WPAC 15\n",
      "WPAC 19\n",
      "WPAC 16\n",
      "Total Time taken: 67.3064949274063 mins\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "for region,v1 in valid_matfile_and_best_track.items():\n",
    "    for year,v2 in v1.items():\n",
    "        print(region,year)\n",
    "        for stormNo,stormDict in v2.items():\n",
    "            for f_,matFiles in stormDict.items():\n",
    "                rootDirOfMatFile = '..\\\\..\\\\CurrentData\\\\Passtimes_and_1C_Data\\\\raw_data\\\\'+year+\"\\\\\"+region+\"\\\\\"+stormNo+\"\\\\passtimes\\\\SSMIS\\\\\"+f_+\"\\\\\"\n",
    "                cdf_tbs = CDF_of_Tbs(rootDirOfMatFile)\n",
    "                for filename,freq_data in matFiles.items():\n",
    "                    cdf_tbs.ReadMatFile(region, filename[:25]+\".mat\",freq_data)\n",
    "print(\"Total Time taken: \"+str( (time.time()-s)/60 )+\" mins\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in rList:\n",
    "    for f in fList:\n",
    "        if 'H' not in f and 'V' not in f:\n",
    "            imgFreq[r][f].to_csv(\"..\\\\ImagesPerFreq_old\\\\\"+r+\"_\"+f+\"PCT.csv\",index=False)\n",
    "        else:\n",
    "            imgFreq[r][f].to_csv(\"..\\\\ImagesPerFreq_old\\\\\"+r+\"_\"+f+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgFreq['ATL']['19H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50\n",
    "149\n",
    "317\n",
    "516\n",
    "634\n",
    "849\n",
    "1002\n",
    "1244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_shp_fname = shpreader.natural_earth(resolution='50m',\n",
    "                                       category='physical', name='land')\n",
    "\n",
    "land_geom = unary_union(list(shpreader.Reader(land_shp_fname).geometries()))\n",
    "land = prep(land_geom)\n",
    "\n",
    "def IsLand(lon,lat):\n",
    "    global land\n",
    "    for x in lon:\n",
    "        for y in lat:\n",
    "            if land.contains(sgeom.Point(x,y)):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def GetSerialDate( normal_date ):\n",
    "    return mpldate.date2num(normal_date)\n",
    "\n",
    "def GetSerialDateFromString( str_name ):\n",
    "    return mpldate.datestr2num(str_name) \n",
    "\n",
    "def MakeDir(path):\n",
    "    if os.path.isdir(path) == False:\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatReader():   \n",
    "    def __init__(self,matpath):\n",
    "        # Will be useful in Child Class\n",
    "        self._mErrors = {}\n",
    "        self._mMatPath = \"..\\\\\"+matpath\n",
    "             \n",
    "    def ReadMatFile(self, matFile):\n",
    "        self._mErrors[0] = [\"Invalid Lat and Lon values     : \",[]]\n",
    "        self._mErrors[1] = [\"Invalid shape of Frequency     : \",[]]\n",
    "        self._mErrors[2] = [\"Invalid Brightness Temperature : \",[]]\n",
    "        self._mErrors[3] = [\"Land found in smaller region   : \",[]]\n",
    "        \n",
    "        try:\n",
    "            mat = scipy.io.loadmat(self._mMatPath+matFile)\n",
    "        except:\n",
    "            msg = \"Error Reading File: \" + str( self._mMatPath+matFile ) \n",
    "            print( msg )\n",
    "            return\n",
    "        \n",
    "        swaths = mat[\"passData\"][0][0]\n",
    "        return swaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_matfile_and_best_track = json.load( open( \"..\\\\valid_matfiles_and_best_track.json\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDF_Of_Tbs:\n",
    "    global tbsVal\n",
    "    def __init__(self, matpath):\n",
    "        self.mMatPath = matpath\n",
    "        \n",
    "        self.__mFreq_to_swath = {}\n",
    "        self.__mFreq_to_swath['19']  = [0,[2.400, 1.400]] \n",
    "        self.__mFreq_to_swath['19V'] = [0,0]\n",
    "        self.__mFreq_to_swath['19H'] = [0,1]\n",
    "        self.__mFreq_to_swath['22V'] = [0,2]\n",
    "\n",
    "        self.__mFreq_to_swath['37']  = [1,[2.150, 1.150]]\n",
    "        self.__mFreq_to_swath['37V'] = [1,0]\n",
    "        self.__mFreq_to_swath['37H'] = [1,1]\n",
    "\n",
    "        self.__mFreq_to_swath['91']  = [3,[1.751, 0.751]]\n",
    "        self.__mFreq_to_swath['91V'] = [3,0] \n",
    "        self.__mFreq_to_swath['91H'] = [3,1]\n",
    "\n",
    "        self.__mFreq_to_swath['150H'] = [2,0]\n",
    "        self.__mFreq_to_swath['183_1H'] = [2,1]\n",
    "        self.__mFreq_to_swath['183_3H'] = [2,2]\n",
    "        self.__mFreq_to_swath['183_7H'] = [2,3]\n",
    "     \n",
    "    def PCT_Function(self,v,h,val):\n",
    "        return val[0]*v - val[1]*h\n",
    "    \n",
    "    def ReadMatFile(self,region,matFile,valid_freq):\n",
    "        try:\n",
    "            mat = scipy.io.loadmat(self.mMatPath+matFile)\n",
    "        except:\n",
    "            msg = \"Error Reading File: \" + str( self.mMatPath+matFile ) \n",
    "            print(msg)\n",
    "            #self.__mLog.error( msg )\n",
    "       \n",
    "        swaths = mat[\"passData\"][0][0]\n",
    "        \n",
    "        for freq in valid_freq:\n",
    "            swathList = self.__mFreq_to_swath[freq]\n",
    "            \n",
    "            swath_data = swaths[ swathList[0] ]\n",
    "            lat = swath_data[0][0][1]\n",
    "            lon = swath_data[0][0][2]\n",
    "            channel = swath_data[0][0][3]\n",
    "            \n",
    "             # Calculating PCT values for specific frequencies\n",
    "            if freq == '19' or freq=='37' or freq=='91':\n",
    "                tbs = self.PCT_Function( channel[0], channel[1], swathList[1] )\n",
    "            else:\n",
    "                tbs = channel[swathList[1]]\n",
    "            \n",
    "            if np.any(tbs<320) and np.any(tbs>0):\n",
    "                tbsVal[region][freq][0].append(np.amin(tbs))\n",
    "                tbsVal[region][freq][1].append(np.amax(tbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
